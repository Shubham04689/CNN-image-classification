{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EX7dr584we6"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjsV_asO4yL_"
      },
      "source": [
        "To identify and classify images as cats or dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwfwDwfu6MXx"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* Load and prepare images for the model using Pytorch\n",
        "* Develop a CNN model and improve model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnkmRa9Uozvd"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The Dogs and Cats dataset is a standard computer vision dataset that involves classifying photos as either containing a dog or cat. The train folder contains ~22k images of dogs and cats. Each image in this folder has the label as part of the filename. The test folder contains ~2k images, named according to a numeric id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6AtEQimwUDU",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e50462-0f81-4f65-d99c-3a8f57032807"
      },
      "source": [
        "#@title Run this cell to download the dataset\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook=\"U3_MH1_CNN_with_Pytorch\" #name of the notebook\n",
        "Answer = \"This notebook is graded by mentors on the day of hackathon\"\n",
        "def setup():\n",
        "#\n",
        "   ipython.magic(\"sx wget http://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Cat_Dog_data_B17.zip\")\n",
        "   ipython.magic(\"sx unzip -qq Cat_Dog_data_B17.zip\")\n",
        "   print (\"Setup completed successfully\")\n",
        "   return\n",
        "\n",
        "setup()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXq346qzqCdh"
      },
      "source": [
        "# Import Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUkNUd_dqIzv"
      },
      "source": [
        "image_size = (128,128)\n",
        "\n",
        "transformations =  transforms.Compose([transforms.Resize(image_size),transforms.Grayscale(num_output_channels=1),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])# YOUR CODE HERE for defining Transformation for an image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6gI08XH2ak"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_set = datasets.ImageFolder('/content/Cat_Dog_data/train', transform = transformations)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (X_train, y_train) in trainloader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzAlYXqD0CAy",
        "outputId": "0c83be67-47d0-4739-fa21-021922227ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([100, 1, 128, 128]) type: torch.FloatTensor\n",
            "y_train: torch.Size([100]) type: torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SeTUS2cPwSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f1d8432d-741d-4643-f984-358dbc6a3d60"
      },
      "source": [
        "\n",
        "labels =[]\n",
        "features = []\n",
        "cats = 0\n",
        "dogs = 0\n",
        "for X,y in zip(X_train, y_train):\n",
        "  # Getting unique labels\n",
        "  if cats<5 or dogs<5:\n",
        "    if cats<5 and y==0:\n",
        "      labels.append(y)\n",
        "      features.append(X)\n",
        "      cats = cats + 1\n",
        "    if dogs<5 and y==1:\n",
        "      labels.append(y)\n",
        "      features.append(X)\n",
        "      dogs = dogs + 1\n",
        "  else:\n",
        "    break\n",
        "\n",
        "labels_map = {0 : 'cat', 1 : 'dog'};\n",
        "pltsize=1\n",
        "plt.figure(figsize=(7,7))\n",
        "for i in range(10):\n",
        "    plt.subplot(4,3, i+1)\n",
        "    plt.axis('off')\n",
        "    # Convert the tensor to numpy for displaying the image\n",
        "    plt.imshow(features[i].numpy().reshape(128,128), cmap=\"gray\")\n",
        "    plt.title('Class: '+labels_map[int(str(labels[i].numpy()))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a99231a72c36>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Getting unique labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdogs\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsCOPyfABc7E"
      },
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Sample Convolution Layer 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2) # output size of the first convolutional layer is 16*128*128 ((input_size+2*padding-kernel_size)/stride)+1\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Sample Maxpool for the Convolutional Layer 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=4) # Maxpooling reduces the size by kernel size. After Maxpooling the output size is 16*32*32\n",
        "\n",
        "\n",
        "        # YOUR CODE HERE for defining more number of Convolutional layers with Maxpool as required (Hint: Use at least 3 convolutional layers for better performance)\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=2) # output size of the first convolutional layer is 16*32*32\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Sample Maxpool for the Convolutional Layer 1\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) # Maxpooling reduces the size by kernel size. After Maxpooling the output size is 32*16*16\n",
        "\n",
        "        self.cnn3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=2) # output size of the first convolutional layer is 16*16*16\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Sample Maxpool for the Convolutional Layer 1\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2) # Maxpooling reduces the size by kernel size. After Maxpooling the output size is 64*8*8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # YOUR CODE HERE for defining the Fully Connected Layer and also define LogSoftmax\n",
        "\n",
        "        self.fc1 = nn.Linear(16*8*8,128)\n",
        "        self.fc3 = nn.Linear(128,32)\n",
        "        self.fc4 = nn.Linear(32,2)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution Layer 1 and Maxpool\n",
        "        #print(f\"1 {x.shape}\")\n",
        "        out = self.cnn1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        #print(f\"2 {out.shape}\")\n",
        "\n",
        "        # YOUR CODE HERE for the Convolutional Layers and Maxpool based on the defined Convolutional layers\n",
        "        out = self.cnn2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "        #print(f\"3 {out.shape}\")\n",
        "\n",
        "        out = self.cnn3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.maxpool3(out)\n",
        "        #print(f\"4 {out.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # YOUR CODE HERE for flattening the output of the final pooling layer to a vector. Flattening is simply arranging the 3D volume of numbers into a 1D vector\n",
        "\n",
        "        out = out.view(-1,16*8*8)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc3(out))\n",
        "        out = self.fc4(out)\n",
        "        out = self.softmax(out)\n",
        "        # YOUR CODE HERE for returning the output of LogSoftmax after applying Fully Connected Layer\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OFWuGmq05ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb16835-29f2-46ec-d732-648f77325b2c"
      },
      "source": [
        "# To run the training on GPU --Rushabh\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "device  =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkt8lKQtCIWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41dfd5a3-48c6-4568-8845-d7f0ef4c3706"
      },
      "source": [
        "model = CNNModel()\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "#criterion = # YOUR CODE HERE : Explore and declare loss function\n",
        "\n",
        "#optimizer = # YOUR CODE HERE : Explore on the optimizer and define with the learning rate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn3): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
            "  (fc4): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_set = datasets.ImageFolder('/content/Cat_Dog_data/test',transform = transformations)\n",
        "# YOUR CODE HERE for the DataLoader\n",
        "testloader = torch.utils.data.DataLoader(val_set, shuffle=True, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "zyYekDCoFi5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ot89MxKavVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babdfbed-7d5a-4f24-87ca-f099af2bae19"
      },
      "source": [
        "# YOUR CODE HERE. This will take time --Anupreksha\n",
        "\n",
        "# Record loss and accuracy of the train dataset\n",
        "epoch = 15\n",
        "\n",
        "# keeping the network in train mode\n",
        "model.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward() # y' = mx+c layer1 w1-> l2 w2-> output (loss) dW1 db1\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Accuracy calculation\n",
        "    train_losses.append(train_loss/len(train_set))\n",
        "    train_accuracy.append(100 * correct/len(train_set))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e+1,train_losses[-1], train_accuracy[-1]))\n",
        "    model.eval()\n",
        "    Test_accuracy = 0\n",
        "    for images,labels in testloader:\n",
        "\n",
        "      # Convert the images and labels to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Do the forward pass\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      Test_accuracy += (predicted == labels).sum().item()\n",
        "    Accuracy = 100 * Test_accuracy / len(val_set)\n",
        "    print(\"Accuracy of Test Data is\", Accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, Train Loss:0.001156 Train Accuracy: 68.96 \n",
            "Accuracy of Test Data is 53.691931540342296\n",
            "epoch: 2, Train Loss:0.001002 Train Accuracy: 75.65 \n",
            "Accuracy of Test Data is 73.49633251833741\n",
            "epoch: 3, Train Loss:0.000906 Train Accuracy: 78.63 \n",
            "Accuracy of Test Data is 78.2885085574572\n",
            "epoch: 4, Train Loss:0.000823 Train Accuracy: 81.11 \n",
            "Accuracy of Test Data is 74.1320293398533\n",
            "epoch: 5, Train Loss:0.000756 Train Accuracy: 82.79 \n",
            "Accuracy of Test Data is 77.75061124694376\n",
            "epoch: 6, Train Loss:0.000728 Train Accuracy: 83.82 \n",
            "Accuracy of Test Data is 80.29339853300733\n",
            "epoch: 7, Train Loss:0.000676 Train Accuracy: 85.15 \n",
            "Accuracy of Test Data is 82.10268948655256\n",
            "epoch: 8, Train Loss:0.000633 Train Accuracy: 86.33 \n",
            "Accuracy of Test Data is 81.9559902200489\n",
            "epoch: 9, Train Loss:0.000617 Train Accuracy: 86.39 \n",
            "Accuracy of Test Data is 78.58190709046455\n",
            "epoch: 10, Train Loss:0.000567 Train Accuracy: 87.88 \n",
            "Accuracy of Test Data is 61.613691931540345\n",
            "epoch: 11, Train Loss:0.000567 Train Accuracy: 88.07 \n",
            "Accuracy of Test Data is 70.75794621026895\n",
            "epoch: 12, Train Loss:0.000556 Train Accuracy: 88.03 \n",
            "Accuracy of Test Data is 66.0635696821516\n",
            "epoch: 13, Train Loss:0.000474 Train Accuracy: 90.04 \n",
            "Accuracy of Test Data is 83.03178484107579\n",
            "epoch: 14, Train Loss:0.000452 Train Accuracy: 90.61 \n",
            "Accuracy of Test Data is 84.10757946210269\n",
            "epoch: 15, Train Loss:0.000446 Train Accuracy: 90.66 \n",
            "Accuracy of Test Data is 65.91687041564792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmBoDOeptJfe"
      },
      "source": [
        "val_set = datasets.ImageFolder('/content/Cat_Dog_data/test',transform = transformations)\n",
        "# YOUR CODE HERE for the DataLoader\n",
        "testloader = torch.utils.data.DataLoader(val_set, shuffle=True, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPZCUolhaE2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726b5c93-ef9a-4a0b-c81d-3d5429a040d7"
      },
      "source": [
        "model.eval()\n",
        "# YOUR CODE HERE for calculating the accuracy\n",
        "Test_accuracy = 0\n",
        "\n",
        "# Iterate through all the batches in each epoch\n",
        "for images,labels in testloader:\n",
        "\n",
        "    # Convert the images and labels to gpu for faster execution\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "print(\"Total correct predictions: \", Test_accuracy)\n",
        "Accuracy = 100 * Test_accuracy / len(val_set)\n",
        "print(\"Accuracy of Test Data is\", Accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions:  1769\n",
            "Accuracy of Test Data is 86.50366748166259\n"
          ]
        }
      ]
    }
  ]
}